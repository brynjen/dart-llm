name: LlamaBindings
description: FFI bindings for llama.cpp
output: 'lib/src/bindings/llama_bindings.dart'

headers:
  entry-points:
    - 'src/include/llama.h'
  include-directives:
    - 'src/include/llama.h'
    - 'src/include/ggml.h'
    - 'src/include/ggml-backend.h'
    - 'src/include/ggml-cpu.h'

preamble: |
  // AUTO-GENERATED FILE. DO NOT MODIFY.
  // 
  // This file was generated by ffigen from llama.h
  // To regenerate: dart run ffigen --config ffigen.yaml

functions:
  include:
    - 'llama_.*'
  exclude:
    - 'llama_grammar_.*'  # Exclude deprecated grammar functions

structs:
  include:
    - 'llama_.*'
  exclude:
    - 'llama_grammar'

enums:
  include:
    - 'llama_.*'
    - 'ggml_type'
    - 'ggml_backend_type'

typedefs:
  include:
    - 'llama_.*'
    - 'ggml_type'

macros:
  include:
    - 'LLAMA_.*'

comments:
  style: any
  length: full

# Silence enum warning - we handle enum sizes appropriately
silence-enum-warning: true

compiler-opts:
  - '-I/home/brynje/git/dart-ollama/packages/llm_llamacpp/src/include'
  - '-I/usr/include'
  - '-DGGML_SHARED'
